{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88f91a1-ef25-481c-94e3-c811824dcb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "619c89de-18f1-4875-936d-e78a751c447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropLayer(object):\n",
    "    def __init__(self, params, blobs):\n",
    "        # initialize our starting and ending (x, y)-coordinates of\n",
    "        # the crop\n",
    "        self.startX = 0\n",
    "        self.startY = 0\n",
    "        self.endX = 0\n",
    "        self.endY = 0   \n",
    "    def getMemoryShapes(self, inputs):\n",
    "        # the crop layer will receive two inputs -- we need to crop\n",
    "        # the first input blob to match the shape of the second one,\n",
    "        # keeping the batch size and number of channels\n",
    "        (inputShape, targetShape) = (inputs[0], inputs[1])\n",
    "        (batchSize, numChannels) = (inputShape[0], inputShape[1])\n",
    "        (H, W) = (targetShape[2], targetShape[3])\n",
    "        # compute the starting and ending crop coordinates\n",
    "        self.startX = int((inputShape[3] - targetShape[3]) / 2)\n",
    "        self.startY = int((inputShape[2] - targetShape[2]) / 2)\n",
    "        self.endX = self.startX + W\n",
    "        self.endY = self.startY + H\n",
    "        # return the shape of the volume (we'll perform the actual\n",
    "        # crop during the forward pass\n",
    "        return [[batchSize, numChannels, H, W]]\n",
    "    def forward(self, inputs):\n",
    "        # use the derived (x, y)-coordinates to perform the crop\n",
    "        return [inputs[0][:, :, self.startY:self.endY,\n",
    "                self.startX:self.endX]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44267506-0712-41e0-b21f-532f4dc4092d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -d EDGE_DETECTOR -i IMAGE\n",
      "ipykernel_launcher.py: error: the following arguments are required: -d/--edge-detector, -i/--image\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[0;31mSystemExit\u001B[0m\u001B[0;31m:\u001B[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartosz/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--edge-detector\", type=str, required=True,\n",
    "\thelp=\"hed_pretrained_bsds.caffemodel\")\n",
    "ap.add_argument(\"-i\", \"--image\", type=str, required=True,\n",
    "\thelp=\"Zdjecia/NET G2, Ki-67 oko≈Ço 5% --copy.jpg\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "\n",
    "# load our serialized edge detector from disk\n",
    "print(\"[INFO] loading edge detector...\")\n",
    "protoPath = os.path.sep.join([args[\"edge_detector\"],\n",
    "\t\"deploy.prototxt\"])\n",
    "modelPath = os.path.sep.join([args[\"edge_detector\"],\n",
    "\t\"hed_pretrained_bsds.caffemodel\"])\n",
    "net = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "# register our new layer with the model\n",
    "cv2.dnn_registerLayer(\"Crop\", CropLayer)\n",
    "\n",
    "\n",
    "# load the input image and grab its dimensions\n",
    "image = cv2.imread(args[\"image\"])\n",
    "(H, W) = image.shape[:2]\n",
    "# convert the image to grayscale, blur it, and perform Canny\n",
    "# edge detection\n",
    "print(\"[INFO] performing Canny edge detection...\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "canny = cv2.Canny(blurred, 30, 150)\n",
    "\n",
    "\n",
    "\n",
    "# construct a blob out of the input image for the Holistically-Nested\n",
    "# Edge Detector\n",
    "blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size=(W, H),\n",
    "\tmean=(104.00698793, 116.66876762, 122.67891434),\n",
    "\tswapRB=False, crop=False)\n",
    "# set the blob as the input to the network and perform a forward pass\n",
    "# to compute the edges\n",
    "print(\"[INFO] performing holistically-nested edge detection...\")\n",
    "net.setInput(blob)\n",
    "hed = net.forward()\n",
    "hed = cv2.resize(hed[0, 0], (W, H))\n",
    "hed = (255 * hed).astype(\"uint8\")\n",
    "# show the output edge detection results for Canny and\n",
    "# Holistically-Nested Edge Detection\n",
    "cv2.imshow(\"Input\", image)\n",
    "cv2.imshow(\"Canny\", canny)\n",
    "cv2.imshow(\"HED\", hed)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
